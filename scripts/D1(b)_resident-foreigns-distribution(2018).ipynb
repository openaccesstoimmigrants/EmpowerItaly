{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a793f383-bd06-40a8-a7c6-a1581ccb2527",
   "metadata": {},
   "source": [
    "# D1(b)\n",
    "## Estimated resident population (2002-2019)\n",
    "### [IstatData](https://esploradati.istat.it/databrowser/#/en/dw/categories/IT1,POP,1.0/POP_INTCENSPOP/DCIS_RICPOPRES2011/IT1,164_164_DF_DCIS_RICPOPRES2011_1,1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b275bf-4246-4d46-ad8d-f2bbf769fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas requests requests_cache xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fddee909-c71e-4928-b042-73d91676a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import xmltodict\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf65eab-f200-4a2c-8841-593342d81994",
   "metadata": {},
   "source": [
    "Since we are interested in a time span of five years (2018-2022), and the data in D1(a) starts at 2019, we are retrieving data from another dataset provided by Istat for information regarding the year 2018.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1234ed9-87a8-471a-b37b-1c420558108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 - Explore Data Structure\n",
    "\n",
    "response = requests.get('https://esploradati.istat.it/SDMXWS/rest/datastructure/IT1/DCIS_RICPOPRES2011/')\n",
    "print(response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.content\n",
    "    \n",
    "    if len(content) > 0:\n",
    "        try:\n",
    "            xml_data = xmltodict.parse(content)\n",
    "            json_string_data = json.dumps(xml_data,\n",
    "                                    allow_nan = True, # If we hadn't set allow_nan to\n",
    "                                                      # true we would have got\n",
    "                                                      # ValueError: Out of range float\n",
    "                                                      # values are not JSON compliant\n",
    "                                    indent = 6) # Indentation can be used for pretty-printing\n",
    "            # Now you can work with the parsed JSON data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"Empty content received.\")\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "\n",
    "# Uncomment the following line to see the resulting JSON string\n",
    "# print(json_string_data)\n",
    "type(json_string_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486eee9-de88-4206-8587-2bb6f062f3a8",
   "metadata": {},
   "source": [
    "By querying the API, we will obtain an XML output that includes the `<structure:DimensionList>` tag, which contains the list of dimensions, i.e., the data schema of the dataset. In our case, the dimensions are as follows: `FREQ`, `REF_AREA`, `DATA_TYPE`, `AGE`, `SEX`, and `CITIZENSHIP`.\n",
    "\n",
    "To understand the meaning of these abbreviations, we can look at the package called `codelist`. It can be queried by the previously discovered IDs. Let's, for example, explore `CITIZENSHIP`. Reading the XML above, we see that the ID to query relative to the package `codelist` is: `CL_CITTADINANZA`. Querying the URL [https://esploradati.istat.it/SDMXWS/rest/codelist/IT1/CL_CITTADINANZA](https://esploradati.istat.it/SDMXWS/rest/codelist/IT1/CL_CITTADINANZA) in Postman (some API responses are too long to be loaded in a Jupyter Notebook), we can see that this dimension is relative to the kind of citizenship. An example of one record is shown below:\n",
    "\n",
    "```xml\n",
    "<structure:Code id=\"FRG\">\n",
    "    <common:Name xml:lang=\"en\">foreign</common:Name>\n",
    "    <common:Name xml:lang=\"it\">straniero-a</common:Name>\n",
    "</structure:Code>\n",
    "```\n",
    "\n",
    "We are interested foreing residentons, and we find that:\n",
    "- `ITL` is the ID for `italian`\n",
    "- `FRG` is the ID for `foreign`\n",
    "- `EU27` is the ID for `of European Union country with 27 Member States`\n",
    "- `EU27_NOITL` is the ID for `of European Union country (except Italy)`\n",
    "- `EXTEU27` is the ID for `of extra European Union country with 27 Member States`\n",
    "- `APO` is the ID for `apolide`\n",
    "- `FRGAPO` is the ID for `foreign/stateless`\n",
    "- `TOTAL` is the ID for `total`al`de>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2374c975-877e-45b1-a467-595b543deaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 2 - Explore the meaning of the dimensions of the dataset\n",
    "\n",
    "response = requests.get('https://esploradati.istat.it/SDMXWS/rest/codelist/IT1/CL_CITTADINANZA')\n",
    "print(response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.content\n",
    "    \n",
    "    if len(content) > 0:\n",
    "        try:\n",
    "            xml_data = xmltodict.parse(content)\n",
    "            json_string_data = json.dumps(xml_data,\n",
    "                                    allow_nan = True, # If we hadn't set allow_nan to\n",
    "                                                      # true we would have got\n",
    "                                                      # ValueError: Out of range float\n",
    "                                                      # values are not JSON compliant\n",
    "                                    indent = 6) # Indentation can be used for pretty-printing\n",
    "            # Now you can work with the parsed JSON data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"Empty content received.\")\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "\n",
    "# Uncomment the following line to see the resulting JSON string\n",
    "# print(json_string_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d5db1-b08c-4783-b3c6-275576082c8f",
   "metadata": {},
   "source": [
    "We explore all the other dimensions and since for our purpose we need all the ages we will have to understand how the are divided and which are the values. In order to do that we need to know the ID of our datasets. We can checkit in the URL on IstatData, and we see that is `164_164_DF_DCIS_RICPOPRES2011_1`.\n",
    "We can query the API rest service like this to obtain our result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c726e51-d479-4a54-8009-5ee59d60b402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 3 - Explore values in Dimensions\n",
    "\n",
    "response = requests.get('https://esploradati.istat.it/SDMXWS/rest/availableconstraint/164_164_DF_DCIS_RICPOPRES2011_1')\n",
    "print(response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.content\n",
    "    \n",
    "    if len(content) > 0:\n",
    "        try:\n",
    "            xml_data = xmltodict.parse(content)\n",
    "            json_string_data = json.dumps(xml_data,\n",
    "                                    allow_nan = True, # If we hadn't set allow_nan to\n",
    "                                                      # true we would have got\n",
    "                                                      # ValueError: Out of range float\n",
    "                                                      # values are not JSON compliant\n",
    "                                    indent = 6) # Indentation can be used for pretty-printing\n",
    "            # Now you can work with the parsed JSON data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"Empty content received.\")\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "\n",
    "# Uncomment the following line to see the resulting JSON string\n",
    "#Â print(json_string_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa2a23-7718-4891-8003-7c554c46040d",
   "metadata": {},
   "source": [
    "We can now compose our final query to retrieve all values relative to the Italian geographical regions for all sexes and all ages. Our final URL will be: `https://esploradati.istat.it/SDMXWS/rest/data/164_164_DF_DCIS_RICPOPRES2011_1/A.IT+ITCD+ITC+ITD+ITE+ITF+ITG.JAN.TOTAL.9.FRG/`\n",
    "\n",
    "The filters we apply after the `data` request are:\n",
    "- `TOTAL` where we specify we want the whole ages not divided\n",
    "- `9` where we specify we want the data not divided by males and females.\n",
    "\n",
    "Since we are interested in geographical regions, we find that:\n",
    "\n",
    "- `ITC` is the ID for the Northwest (`nord-ovest` in Italian)\n",
    "- `ITD` is the ID for the Northeast (`nord-est` in Italian)\n",
    "- `ITCD` is the ID for the North (`nord` in Italian)\n",
    "- `ITE` is the ID for the Center (`centro` in Italian)\n",
    "- `ITF` is the ID for the South (`sud` in Italian)\n",
    "- `ITG` is the ID for the Islands, including Sardinia and Sicily (`isole` in Italian)\n",
    "- `IT` is the ID for the whole `Italy` (`Italia` in Italian)\n",
    "\n",
    "We will need these IDs for our API request for this dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "914cc97f-57de-485a-8d2e-27208405fdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 4 -  Final query with filters\n",
    "\n",
    "response = requests.get('https://esploradati.istat.it/SDMXWS/rest/data/164_164_DF_DCIS_RICPOPRES2011_1/A.IT+ITCD+ITC+ITD+ITE+ITF+ITG.JAN.TOTAL.9.FRG/')\n",
    "print(response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.content\n",
    "    \n",
    "    if len(content) > 0:\n",
    "        try:\n",
    "            xml_data = xmltodict.parse(content)\n",
    "            json_string_data = json.dumps(xml_data,\n",
    "                                    allow_nan = True, # If we hadn't set allow_nan to\n",
    "                                                      # true we would have got\n",
    "                                                      # ValueError: Out of range float\n",
    "                                                      # values are not JSON compliant\n",
    "                                    indent = 6) # Indentation can be used for pretty-printing\n",
    "            # Now you can work with the parsed JSON data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"Empty content received.\")\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "\n",
    "# Print is disable in documentation since the response is too long to be shown here. Uncomment to see it.\n",
    "# print(json_string_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2dc08-7e2a-4625-be5b-e6b323a24e94",
   "metadata": {},
   "source": [
    "Now we crate a well formed JSON sting from the response.\n",
    "\n",
    "The code snippet performs the following tasks:\n",
    "\n",
    "1. It takes a JSON string called `json_string_data` and creates a nested dictionary, `nested_dict`, using the `json.loads()` function. This step is essential to process and extract information from the JSON data.\n",
    "\n",
    "2. It defines a translation dictionary, `sex_translation`, which maps numeric codes to corresponding gender labels ('1' to 'Male' and '2' to 'Female'). This dictionary will be used to translate the sex values later.\n",
    "\n",
    "3. It initializes an empty list, `result`, which will store the extracted information from the nested dictionary.\n",
    "\n",
    "4. It iterates over the series data in the nested dictionary. Each series represents a set of observations for a specific combination of variables.\n",
    "\n",
    "5. Within each series, it retrieves the territory and sex values by searching for specific keys ('ITTER107' and 'SESSO') in the series key. If found, it assigns the corresponding values to the `territory` and `sex` variables, respectively. The sex value is translated using the `sex_translation` dictionary.\n",
    "\n",
    "6. It retrieves the observation values (`obs_values`) for each series and iterates over them. Each observation contains information about the year, age, and quantity.\n",
    "\n",
    "7. It creates an entry dictionary that contains the extracted information, including the territory, year, sex, age, and quantity.\n",
    "\n",
    "8. The entry dictionary is appended to the `result` list.\n",
    "\n",
    "9. Finally, the `result` list is converted to a JSON string, `immigrants_distribution_2018`, using `json.dumps()`. The type of the `immigrants_distribution_2018` variable is printed to verify that it is a string.\n",
    "\n",
    "In summary, sintethis code processes the nested dictionary, extracts specific information, translates values, and organizes the extracted data into a clean JSON format suitable for visualization or further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6953301e-5042-4aae-8e99-2e10e5b04df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a nested dictonary from the response in order to create a clean JSON for our visualization\n",
    "\n",
    "nested_dict = json.loads(json_string_data)\n",
    "\n",
    "# Translation dictionary\n",
    "sex_translation = {\n",
    "    '1': 'Male',\n",
    "    '2': 'Female',\n",
    "    '9': 'TOTAL'\n",
    "}\n",
    "\n",
    "# Extracting information\n",
    "result = []\n",
    "\n",
    "series_data = nested_dict['message:GenericData']['message:DataSet']['generic:Series']\n",
    "for series in series_data:\n",
    "    series_key = series['generic:SeriesKey']\n",
    "    territory = None\n",
    "    sex = None\n",
    "\n",
    "    for value in series_key['generic:Value']:\n",
    "        if value['@id'] == 'REF_AREA':\n",
    "            territory = value['@value']\n",
    "        elif value['@id'] == 'SEX':\n",
    "            sex_value = value['@value']\n",
    "            sex = sex_translation.get(sex_value)\n",
    "\n",
    "    obs_values = series['generic:Obs']\n",
    "    for obs in obs_values:\n",
    "        year = obs['generic:ObsDimension']['@value']\n",
    "        age = series_key['generic:Value'][3]['@value']\n",
    "        quantity = obs['generic:ObsValue']['@value']\n",
    "\n",
    "        entry = {\n",
    "            'Territory': territory,\n",
    "            'Year': int(year),\n",
    "            'Sex': sex,\n",
    "            'Age': age,\n",
    "            'Quantity': int(quantity)\n",
    "        }\n",
    "        result.append(entry)\n",
    "\n",
    "# Convert result to JSON\n",
    "immigrants_distribution_2018 = json.dumps(result)\n",
    "\n",
    "# Uncomment the following line to see the resulting JSON string\n",
    "# print(immigrants_distribution_2018)\n",
    "type(immigrants_distribution_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9055d97a-fc0b-4980-a6b1-a3a7311e2f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data for 2018 saved as filtered_immigrants_distribution_2018.json\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON dataset\n",
    "data = immigrants_distribution_2018\n",
    "\n",
    "# Ensure data is parsed as a list of dictionaries\n",
    "if isinstance(data, str):\n",
    "    data = json.loads(data)\n",
    "\n",
    "# Use a list comprehension to filter data for the year 2018\n",
    "data_2018 = [entry for entry in data if entry[\"Year\"] == 2018]\n",
    "\n",
    "# Specify the folder path to save the JSON file\n",
    "folder_path = \"../_datasets/Clean/D1(b)\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Define the file path for the output JSON file\n",
    "filename = \"filtered_immigrants_distribution_2018.json\"\n",
    "\n",
    "# Generate the file path\n",
    "file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Save the filtered data as a JSON file with the same name\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(data_2018, json_file, indent=4)\n",
    "\n",
    "print(f\"Filtered data for 2018 saved as {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bba8a-2e13-41e6-954b-5a18e26f60d7",
   "metadata": {},
   "source": [
    "After saving the JSON data related to 2018, we merge it with the other data related to 2019 till 2022, retrieved from the other dataset D1(a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "539e1c3b-a8dd-46e3-89b7-8f1399a699b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved as combined_immigrants_distribution.json\n"
     ]
    }
   ],
   "source": [
    "# Let's create a single json adding 2018's data with the other years\n",
    "\n",
    "# Load the JSON file with data for other years\n",
    "with open(\"../_datasets/Clean/D1(a)/immigrants_distribution.json\", \"r\") as file:\n",
    "    data_other_years = json.load(file)\n",
    "\n",
    "# Combine the data from both files into a single list\n",
    "combined_data = data_other_years + data_2018\n",
    "\n",
    "sorted_data = sorted(combined_data, key=lambda x: x['Year'])\n",
    "\n",
    "# Specify the folder path to save the combined JSON file\n",
    "folder_path = \"../_datasets/Clean/D1(b)\"\n",
    "\n",
    "# Define the file path for the output JSON file\n",
    "filename = \"combined_immigrants_distribution.json\"\n",
    "\n",
    "# Generate the file path\n",
    "file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Save the combined data as a new JSON file\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(sorted_data, json_file, indent=4)\n",
    "\n",
    "print(f\"Combined data saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81028d29-1ce9-45ee-82d9-29db1bf73406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
