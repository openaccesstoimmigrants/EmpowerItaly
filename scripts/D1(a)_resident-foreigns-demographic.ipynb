{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a793f383-bd06-40a8-a7c6-a1581ccb2527",
   "metadata": {},
   "source": [
    "# D2\n",
    "## ISTAT SDMX - Resident foreigners on 1st January\n",
    "\n",
    "[See on IstatData](https://esploradati.istat.it/databrowser/#/it/dw/categories/IT1,POP,1.0/POP_FOREIGNIM/DCIS_POPSTRRES1/IT1,29_7_DF_DCIS_POPSTRRES1_1,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b275bf-4246-4d46-ad8d-f2bbf769fa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandasdmx in /usr/local/lib/python3.11/site-packages (1.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: requests_cache in /usr/local/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: xmltodict in /usr/local/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: lxml>=4.1 in /usr/local/lib/python3.11/site-packages (from pandasdmx) (4.9.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/site-packages (from pandasdmx) (2.0.2)\n",
      "Requirement already satisfied: pydantic<2.0,>=1.9.2 in /usr/local/lib/python3.11/site-packages (from pandasdmx) (1.10.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.11/site-packages (from requests_cache) (23.1.0)\n",
      "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.11/site-packages (from requests_cache) (23.1.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/site-packages (from requests_cache) (3.5.1)\n",
      "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.11/site-packages (from requests_cache) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas>=1.2->pandasdmx) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas>=1.2->pandasdmx) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/site-packages (from pandas>=1.2->pandasdmx) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/site-packages (from pandas>=1.2->pandasdmx) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/site-packages (from pydantic<2.0,>=1.9.2->pandasdmx) (4.6.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/site-packages (from url-normalize>=1.4->requests_cache) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install pandasdmx requests requests_cache xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d72ee9-a8d2-4c2e-92dd-b6ef90f15629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasdmx as sdmx\n",
    "import json\n",
    "import requests\n",
    "# from pandasdmx import Request\n",
    "import xmltodict\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1234ed9-87a8-471a-b37b-1c420558108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 -  EXPLORE DATASTRUCTURE\n",
    "response = requests.get('http://sdmx.istat.it/SDMXWS/rest/datastructure/IT1/DCIS_POPSTRRES1/')\n",
    "print(response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.content\n",
    "    \n",
    "    if len(content) > 0:\n",
    "        try:\n",
    "            xml_data = xmltodict.parse(content)\n",
    "            json_string_data = json.dumps(xml_data,\n",
    "                                    allow_nan = True, # If we hadn't set allow_nan to\n",
    "                                                      # true we would have got\n",
    "                                                      # ValueError: Out of range float\n",
    "                                                      # values are not JSON compliant\n",
    "                                    indent = 6) # Indentation can be used for pretty-printing\n",
    "            # Now you can work with the parsed JSON data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"Empty content received.\")\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "\n",
    "# print(json_string_data)\n",
    "type(json_string_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486eee9-de88-4206-8587-2bb6f062f3a8",
   "metadata": {},
   "source": [
    "By querying the API, we will obtain an XML output that includes the structure:DimensionList tag, which contains the list of dimensions, i.e., the data schema of the dataset. In our case, the dimensions are as follows: `FREQ`, `ETA`, `ITTER107`, `SESSO`, `TIPO_INDDEM` and `TIME_PERIOD`.\n",
    "\n",
    "To understand the meaning of this abbreviations we can look at the package called `codelist`. It can be queried by the previous discovered IDs. Let's for example explore `ITTER107`. Reading the XML above we see that the ID to query relative to the package `codelist` is: `CL_ITTER107`. Querying the URL `http://sdmx.istat.it/SDMXWS/rest/codelist/IT1/CL_ITTER107` in Postman (some API response are too long to be loaded in a Jupyter Notebook) we can see that this dimension is relative to the territory of Italy and all Italian Municipality are listed with full name and ID. An example of one record is shown below:\n",
    "\n",
    "\n",
    "`<structure:Code id=\"SLL_2011_116\" urn=\"urn:sdmx:org.sdmx.infomodel.codelist.Code=IT1:CL_ITTER107(5.6).SLL_2011_116\">`\n",
    "<br>\n",
    "`    <common:Name xml:lang=\"it\">Fossano</common:Name>`\n",
    "    <br>\n",
    "`    <common:Name xml:lang=\"en\">Fossano</common:Name>`\n",
    "    <br>\n",
    "`    <structure:Parent>`\n",
    "    <br>\n",
    "`        <Ref id=\"IT\" />`\n",
    "        <br>\n",
    "`    </structure:Parent>`\n",
    "    <br>\n",
    "`</structure:Code>`\n",
    "\n",
    "Since we are interested in just Italy, we find that `IT` is the ID we will need for our API request for this dimension:Code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2374c975-877e-45b1-a467-595b543deaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 2 - Explore the meaning of the dimensions of the dataset\n",
    "\n",
    "response = requests.get('http://sdmx.istat.it/SDMXWS/rest/codelist/IT1/CL_ITTER107')\n",
    "print(response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.content\n",
    "    \n",
    "    if len(content) > 0:\n",
    "        try:\n",
    "            xml_data = xmltodict.parse(content)\n",
    "            json_string_data = json.dumps(xml_data,\n",
    "                                    allow_nan = True, # If we hadn't set allow_nan to\n",
    "                                                      # true we would have got\n",
    "                                                      # ValueError: Out of range float\n",
    "                                                      # values are not JSON compliant\n",
    "                                    indent = 6) # Indentation can be used for pretty-printing\n",
    "            # Now you can work with the parsed JSON data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"Empty content received.\")\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "\n",
    "# print(json_string_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d5db1-b08c-4783-b3c6-275576082c8f",
   "metadata": {},
   "source": [
    "We explore all the other dimensions and since for our purpose we need all the ages we will have to understand how the are divided and which are the values. In order to do that we need to know the ID of our datasets. We can checkit in the URL on IstatData, and we see that is `29_7`.\n",
    "We can query the API rest service like this to obtain our result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c726e51-d479-4a54-8009-5ee59d60b402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 3 -  EXPLORE VALUES IN DIMENSIONS\n",
    "response = requests.get('http://sdmx.istat.it/SDMXWS/rest/availableconstraint/29_7')\n",
    "print(response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.content\n",
    "    \n",
    "    if len(content) > 0:\n",
    "        try:\n",
    "            xml_data = xmltodict.parse(content)\n",
    "            json_string_data = json.dumps(xml_data,\n",
    "                                    allow_nan = True, # If we hadn't set allow_nan to\n",
    "                                                      # true we would have got\n",
    "                                                      # ValueError: Out of range float\n",
    "                                                      # values are not JSON compliant\n",
    "                                    indent = 6) # Indentation can be used for pretty-printing\n",
    "            # Now you can work with the parsed JSON data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"Empty content received.\")\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "\n",
    "# Print is disable in documentation since the response is too long to be shown here. Uncomment to see it.\n",
    "# print(json_string_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa2a23-7718-4891-8003-7c554c46040d",
   "metadata": {},
   "source": [
    "We can now compose our final query for retrive all values relative of all ages, for all Italy, divided by sex.\n",
    "Our final URL will be: http://sdmx.istat.it/SDMXWS/rest/data/29_7/..IT.1+2./\n",
    "\n",
    "The filters we apply after the `data` request are: `IT`that is equal to whole Italian nation, and `1+2`where we specify we want the data divided by males (1) and females (2). When you see just the period `.` it means the filter is not specified, so in our case, we are requesting all ages (from `Y0` to `Y_GE100`) of all available time periods (from  2019 to 2022)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "914cc97f-57de-485a-8d2e-27208405fdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 4 -  FINAL QUERY WITH FILTERS\n",
    "response = requests.get('http://sdmx.istat.it/SDMXWS/rest/data/29_7/..IT.1+2./')\n",
    "print(response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.content\n",
    "    \n",
    "    if len(content) > 0:\n",
    "        try:\n",
    "            xml_data = xmltodict.parse(content)\n",
    "            json_string_data = json.dumps(xml_data,\n",
    "                                    allow_nan = True, # If we hadn't set allow_nan to\n",
    "                                                      # true we would have got\n",
    "                                                      # ValueError: Out of range float\n",
    "                                                      # values are not JSON compliant\n",
    "                                    indent = 6) # Indentation can be used for pretty-printing\n",
    "            # Now you can work with the parsed JSON data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"Empty content received.\")\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "\n",
    "# Print is disable in documentation since the response is too long to be shown here. Uncomment to see it.\n",
    "# print(json_string_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2dc08-7e2a-4625-be5b-e6b323a24e94",
   "metadata": {},
   "source": [
    "Now we crate a well formed JSON sting from the response.\n",
    "\n",
    "The code snippet performs the following tasks:\n",
    "\n",
    "1. It takes a JSON string called `json_string_data` and creates a nested dictionary, `nested_dict`, using the `json.loads()` function. This step is essential to process and extract information from the JSON data.\n",
    "\n",
    "2. It defines a translation dictionary, `sex_translation`, which maps numeric codes to corresponding gender labels ('1' to 'Male' and '2' to 'Female'). This dictionary will be used to translate the sex values later.\n",
    "\n",
    "3. It initializes an empty list, `result`, which will store the extracted information from the nested dictionary.\n",
    "\n",
    "4. It iterates over the series data in the nested dictionary. Each series represents a set of observations for a specific combination of variables.\n",
    "\n",
    "5. Within each series, it retrieves the territory and sex values by searching for specific keys ('ITTER107' and 'SESSO') in the series key. If found, it assigns the corresponding values to the `territory` and `sex` variables, respectively. The sex value is translated using the `sex_translation` dictionary.\n",
    "\n",
    "6. It retrieves the observation values (`obs_values`) for each series and iterates over them. Each observation contains information about the year, age, and quantity.\n",
    "\n",
    "7. It creates an entry dictionary that contains the extracted information, including the territory, year, sex, age, and quantity.\n",
    "\n",
    "8. The entry dictionary is appended to the `result` list.\n",
    "\n",
    "9. Finally, the `result` list is converted to a JSON string, `immigrants_demographic`, using `json.dumps()`. The type of the `immigrants_demographic` variable is printed to verify that it is a string.\n",
    "\n",
    "In summary, sintethis code processes the nested dictionary, extracts specific information, translates values, and organizes the extracted data into a clean JSON format suitable for visualization or further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6953301e-5042-4aae-8e99-2e10e5b04df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Creating a nested dictonary from the response in order to create a clean JSON for our visualization\n",
    "nested_dict = json.loads(json_string_data)\n",
    "\n",
    "# Translation dictionary\n",
    "sex_translation = {\n",
    "    '1': 'Male',\n",
    "    '2': 'Female'\n",
    "}\n",
    "\n",
    "# Extracting information\n",
    "result = []\n",
    "\n",
    "series_data = nested_dict['message:GenericData']['message:DataSet']['generic:Series']\n",
    "for series in series_data:\n",
    "    series_key = series['generic:SeriesKey']\n",
    "    territory = None\n",
    "    sex = None\n",
    "\n",
    "    for value in series_key['generic:Value']:\n",
    "        if value['@id'] == 'ITTER107':\n",
    "            territory = value['@value']\n",
    "        elif value['@id'] == 'SESSO':\n",
    "            sex_value = value['@value']\n",
    "            sex = sex_translation.get(sex_value)\n",
    "\n",
    "    obs_values = series['generic:Obs']\n",
    "    for obs in obs_values:\n",
    "        year = obs['generic:ObsDimension']['@value']\n",
    "        age = series_key['generic:Value'][1]['@value']\n",
    "        quantity = obs['generic:ObsValue']['@value']\n",
    "\n",
    "        entry = {\n",
    "            'Territory': territory,\n",
    "            'Year': int(year),\n",
    "            'Sex': sex,\n",
    "            'Age': age,\n",
    "            'Quantity': int(quantity)\n",
    "        }\n",
    "        result.append(entry)\n",
    "\n",
    "# Convert result to JSON\n",
    "immigrants_demographic = json.dumps(result)\n",
    "print(type(immigrants_demographic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bba8a-2e13-41e6-954b-5a18e26f60d7",
   "metadata": {},
   "source": [
    "The next code snippet performs the following tasks:\n",
    "\n",
    "1. It converts the `immigrants_demographic` string, which contains a JSON representation, into a JSON object using `json.loads()`. This step allows easier manipulation and access to the data.\n",
    "\n",
    "2. It specifies the folder path where the resulting JSON file will be saved. In this case, the folder path is \"../_datasets/Clean\".\n",
    "\n",
    "3. It creates the specified folder if it does not already exist using `os.makedirs()`. This ensures that the folder is available to store the JSON file.\n",
    "\n",
    "4. It defines the filename for the JSON file as \"immigrants_demographic.json\".\n",
    "\n",
    "5. It generates the complete file path by joining the folder path and filename using `os.path.join()`.\n",
    "\n",
    "6. It saves the `immigrants_demographic_json` JSON object to a file specified by the file path. This is achieved using `json.dump()` with the file opened in write mode (\"w\").\n",
    "\n",
    "7. The JSON data is formatted with an indent of 4 spaces to improve readability within the file.\n",
    "\n",
    "8. Finally, it prints a message confirming the successful saving of the JSON data, along with the file path where it was saved.\n",
    "\n",
    "So basically this code snippet takes a JSON object, saves it as a JSON file in a specified directory, and provides feedback on the successful saving of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "785532af-7dd4-4cab-bac1-b75b68c67c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data saved to: ../_datasets/Clean/immigrants_demographic.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert immigrants_demographic string to JSON object\n",
    "immigrants_demographic_json = json.loads(immigrants_demographic)\n",
    "\n",
    "# Specify the folder path to save the JSON file\n",
    "folder_path = \"../_datasets/Clean\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Define the filename for the JSON file\n",
    "filename = \"immigrants_demographic.json\"\n",
    "\n",
    "# Generate the file path\n",
    "file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Save the immigrants_demographic JSON object to file\n",
    "with open(file_path, \"w\") as file:\n",
    "    json.dump(immigrants_demographic_json, file, indent=4)\n",
    "\n",
    "print(f\"JSON data saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091e053-3f88-4fec-89be-f1f7ebcf6514",
   "metadata": {},
   "source": [
    "The last code snippet loads a JSON file, modifies the \"Age\" values by removing a \"Y\" prefix if present, and saves the modified data back to the same JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb29c391-1557-480a-b698-a3098a199efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data saved to: ../_datasets/Clean/immigrants_demographic.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Specify the path to the JSON file\n",
    "file_path = \"../_datasets/Clean/immigrants_demographic.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Iterate over the entries and modify the Age values\n",
    "for entry in data:\n",
    "    age = entry[\"Age\"]\n",
    "    if age.startswith(\"Y\") and age[1:].isdigit():\n",
    "        entry[\"Age\"] = age[1:]\n",
    "\n",
    "# Save the modified data back to the JSON file\n",
    "with open(file_path, \"w\") as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(f\"JSON data saved to: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc88a1da-6ee8-4a6a-8e19-6dead3c74bd1",
   "metadata": {},
   "source": [
    "# CALCULATE IMMIGRANTS MEDIUM AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e974a52-20d1-45e4-ac9f-f8f554b84a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query all foreinger residents, both sexes, total divided by age and all marital status.\n",
    "response_age = requests.get('https://esploradati.istat.it/SDMXWS/rest/data/29_7/A.IT.9.JAN..')\n",
    "print(response_age.status_code)\n",
    "\n",
    "if response_age.status_code == 200:\n",
    "    content = response_age.content\n",
    "    \n",
    "    if len(content) > 0:\n",
    "        try:\n",
    "            xml_data = xmltodict.parse(content)\n",
    "            json_string_data_age = json.dumps(xml_data,\n",
    "                                    allow_nan = True, # If we hadn't set allow_nan to\n",
    "                                                      # true we would have got\n",
    "                                                      # ValueError: Out of range float\n",
    "                                                      # values are not JSON compliant\n",
    "                                    indent = 6) # Indentation can be used for pretty-printing\n",
    "            # Now you can work with the parsed JSON data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"Empty content received.\")\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "\n",
    "print(json_string_data_age)\n",
    "type(json_string_data_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76245cb0-8aad-470c-b817-c55a0f32caae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list to store age data\n",
    "age_data = []\n",
    "\n",
    "# Parse the JSON string into a dictionary\n",
    "age_data_dict = json.loads(json_string_data_age)\n",
    "\n",
    "# Extract the series data\n",
    "series = age_data_dict[\"message:GenericData\"][\"message:DataSet\"][\"generic:Series\"]\n",
    "\n",
    "for series_data in series:\n",
    "    series_key = series_data[\"generic:SeriesKey\"]\n",
    "    obs_list = series_data[\"generic:Obs\"]\n",
    "\n",
    "    # Extract territory (REF_AREA)\n",
    "    territory = None\n",
    "    for key in series_key[\"generic:Value\"]:\n",
    "        if key[\"@id\"] == \"REF_AREA\":\n",
    "            territory = key[\"@value\"]\n",
    "            break\n",
    "\n",
    "    for obs in obs_list:\n",
    "        # Extract age from SeriesKey\n",
    "        age_key = next(\n",
    "            (value for value in series_key[\"generic:Value\"] if value[\"@id\"] == \"AGE\"),\n",
    "            None,\n",
    "        )\n",
    "\n",
    "        # Skip the age \"TOTAL\"\n",
    "        if age_key and age_key[\"@value\"] != \"TOTAL\":\n",
    "            time_period = int(obs[\"generic:ObsDimension\"][\"@value\"])  # Convert to integer\n",
    "            obs_value = int(obs[\"generic:ObsValue\"][\"@value\"])  # Convert to integer\n",
    "\n",
    "            # Handle the exception for age \"Y_GE100\"\n",
    "            age = age_key[\"@value\"]\n",
    "            if age == \"Y_GE100\":\n",
    "                age = 100  # Set the age to \"100 or more\"\n",
    "            else:\n",
    "                # Translate age to a string by removing the 'Y'\n",
    "                age = int(age[1:])  # Convert to a string after removing 'Y'\n",
    "\n",
    "            # Store the data by age\n",
    "            age_data.append({\n",
    "                \"AGE\": age,\n",
    "                \"YEAR\": time_period,\n",
    "                \"POPULATION\": obs_value,\n",
    "            })\n",
    "\n",
    "# Convert the age data to JSON\n",
    "resident_immigrant_population_age_json = json.dumps(age_data, indent=4)\n",
    "\n",
    "# print(resident_italian_population_age_json)\n",
    "type(resident_immigrant_population_age_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d591dfe-3896-42ab-b2e3-a8e2015a5673",
   "metadata": {},
   "source": [
    "## ATTENTION: Istat doesn't distinguish beetween the age 100 or more, the all gruopped under \"Y_GE100\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c07a0bb2-9c38-4dd6-8395-5d4d61c6f624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data saved to: ../_datasets/Clean/D1/resident_immigrant_population_age.json\n"
     ]
    }
   ],
   "source": [
    "# Save the new file\n",
    "\n",
    "# Specify the folder path to save the JSON file\n",
    "folder_path = \"../_datasets/Clean/D1(a)\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Define the filename for the JSON file\n",
    "filename = \"resident_immigrant_population_age.json\"\n",
    "\n",
    "# Generate the file path\n",
    "file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Save the resident Italian population JSON to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(resident_immigrant_population_age_json)\n",
    "\n",
    "print(f\"JSON data saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f403c5ec-980e-44c1-b63e-b79faf9a7fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
