{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f771b03",
   "metadata": {},
   "source": [
    "# D1\n",
    "## ISTAT SDMX - Migration (Transfer of residence)\n",
    "\n",
    "[See on IstatData](https://esploradati.istat.it/databrowser/#/it/dw/categories/IT1,POP,1.0/POP_MIGRATIONS/DCIS_MIGRAZIONI/IT1,28_185_DF_DCIS_MIGRAZIONI_3,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b275bf-4246-4d46-ad8d-f2bbf769fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandasdmx requests requests_cache xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d72ee9-a8d2-4c2e-92dd-b6ef90f15629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasdmx as sdmx\n",
    "import json\n",
    "import requests\n",
    "# from pandasdmx import Request\n",
    "import xmltodict\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1ab1d",
   "metadata": {},
   "source": [
    "We start testing the API for just the immigrants from Africa. We also specify filters in the final part of the url, after the ID of the table, in our case '28_185'. Precisily we will operate on the dimension that are been explored before. The exploratory part of the data is easly to handle with software like Postman.\n",
    "\n",
    "## 1 - Explore datastructure\n",
    "\n",
    "`https://esploradati.istat.it/SDMXWS/rest/datastructure/IT1/DCIS_MIGRAZIONI/`\n",
    "\n",
    "## 2 - The meaning of the dimensions of the dataset\n",
    "\n",
    "`https://esploradati.istat.it/SDMXWS/rest/codelist/IT1/CL_PROV_DEST_Z`\n",
    "\n",
    "`https://esploradati.istat.it/SDMXWS/rest/codelist/IT1/CL_TIPO_DATO15`\n",
    "cure:Code>de>\n",
    "\n",
    "## 3 - Explore values\n",
    " in dimensionhttps://esploradati.istat.it/SDMXWS/rest/availableconstrai\n",
    "\n",
    "Since not all values shown in meaning odf the dimensions seen above, we need to understand, for our dataset, which are the available constraints of each dimension in our dataset.nt/28_185/1\n",
    "\n",
    "Here we see the different filters we can apply to the dfferent diimensions.\n",
    "We have:\n",
    "- \"FREQ\" for frequency, in this case the data is collected on an annual base so the only value availabe is \"A\", annual.\n",
    "- \"REF_ARETerritory of previous residence related to Italy, for us will be empty since we are interested not in internal migrationd By default \"ITTOT\" will be selected, meanign that the whole Italy will be taken in consideration. Sardinia).\n",
    "- \"is an indicator related to the kind of data we are interested, there are just three available for this dataset:\"CORE\" changes of residence, \"TDEREG\" deregistrations and \"TREG\" registration. We will look at the last one.\n",
    "- \"CHANGE_OF_RESIDENCE\" meaning from where the person is migrated, we are interested in only foreigners, so for us the filter will be \"FREIGN\".\n",
    "- \"CITIZENSHIP\" whete the geopolitical origin is declared, we will select by continent making a distinction only between EU27 and ExtraEU27. We will filter for: \"EU27_FOR\", \"EUR_NEU27\", \"AFR\", \"ASI\", \"AME\" and \"OCE\".\n",
    "- \"SEX\" we are interested in the total, so for us will be \"9\".\n",
    "- \"AGE\" total again so \"TOTAL\".\n",
    "- \"TERRITORY_NEXT_RESID\" for the new residence's geographic area. In our case we decided to look at group of regions, level NUTS 1 (Nomenclature of Territorial Units for Statistics). So we filter for: ITC for Northwest Italy; ITD for Northeast Italy; ITE for Central Italy; ITF for South Italy; ITG Insular Italy (Sicily and Sardinia).\n",
    "- \"COUNTRY_PREV_RESID\" we select World since we are not iinterested in one particular value, the code will be \"X1033\".\n",
    "- \"COUNTRY_NEXT_RESID\" we select World since we are not iinterested in one particular value, the code will be \"X1033\".\n",
    "\n",
    "## 4 - Query with filters\n",
    "\n",
    "`https://esploradati.istat.it/SDMXWS/rest/data/28_185/A..TREG.FREIGN.EU27_FOR+EUR_NEU27+AFR+ASI+AME+OCE.9.TOTAL.ITTOT.X1033.X1033`T.ITTOT....9.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f656c24-05ac-4088-aa9e-1589b016f421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 - QUERY WITH FILTERS\n",
    "# Query all immigrants, both sexes, every age, in the whole Italy divided by continet of citizenship.\n",
    "response = requests.get('https://esploradati.istat.it/SDMXWS/rest/data/28_185/A..TREG.FREIGN.EU27_FOR+EUR_NEU27+AFR+ASI+AME+OCE.9.TOTAL.ITTOT.X1033.X1033')\n",
    "print(response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.content\n",
    "    \n",
    "    if len(content) > 0:\n",
    "        try:\n",
    "            xml_data = xmltodict.parse(content)\n",
    "            json_string_data = json.dumps(xml_data,\n",
    "                                    allow_nan = True, # If we hadn't set allow_nan to\n",
    "                                                      # true we would have got\n",
    "                                                      # ValueError: Out of range float\n",
    "                                                      # values are not JSON compliant\n",
    "                                    indent = 6) # Indentation can be used for pretty-printing\n",
    "            # Now you can work with the parsed JSON data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"Empty content received.\")\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "\n",
    "# print(json_string_data)\n",
    "type(json_string_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6953301e-5042-4aae-8e99-2e10e5b04df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the JSON-like string\n",
    "nested_dict = json.loads(json_string_data)\n",
    "\n",
    "# Accessing values in the nested dictionary\n",
    "header_id = nested_dict['message:GenericData']['message:Header']['message:ID']\n",
    "dataset_action = nested_dict['message:GenericData']['message:DataSet']['@action']\n",
    "series = nested_dict['message:GenericData']['message:DataSet']['generic:Series']\n",
    "obs_values = []\n",
    "\n",
    "# Access each observation in the series\n",
    "for observation in series[0]['generic:Obs']:\n",
    "    obs_dimension = observation['generic:ObsDimension']\n",
    "    obs_value = observation['generic:ObsValue']\n",
    "    obs_values.append({\n",
    "        obs_dimension['@id']: obs_dimension['@value'],\n",
    "        'value': obs_value['@value']\n",
    "    })\n",
    "\n",
    "# Print the entire nested_dict with indentation\n",
    "# print(json.dumps(nested_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc73f5ae-3e07-40e6-b463-e7058d7aab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the JSON-like string\n",
    "data = json.loads(json_string_data)\n",
    "\n",
    "continent_data = {}\n",
    "\n",
    "series = data['message:GenericData']['message:DataSet']['generic:Series']\n",
    "\n",
    "for s in series:\n",
    "    series_key = s['generic:SeriesKey']['generic:Value']\n",
    "    obs = s['generic:Obs']\n",
    "\n",
    "    continent = None\n",
    "\n",
    "    for key in series_key:\n",
    "        if key['@id'] == 'CITIZENSHIP':\n",
    "            continent = key['@value']\n",
    "            break\n",
    "\n",
    "    if continent:\n",
    "        if continent not in continent_data:\n",
    "            continent_data[continent] = []\n",
    "\n",
    "        for o in obs:\n",
    "            year = int(o['generic:ObsDimension']['@value'])\n",
    "            value = o['generic:ObsValue']['@value']\n",
    "\n",
    "            # Set the year as a date type with the last day of the year\n",
    "            year_date = datetime(year=year, month=12, day=31)\n",
    "\n",
    "            continent_data[continent].append({\"year\": year_date.strftime(\"%Y-%m-%d\"), \"tot_immigrants\": int(value)})\n",
    "\n",
    "# Convert the continent data to JSON\n",
    "continent_json = json.dumps(continent_data, indent=4)\n",
    "\n",
    "# print(continent_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "785532af-7dd4-4cab-bac1-b75b68c67c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data saved to: ../_datasets/Clean/continent_data_2.json\n"
     ]
    }
   ],
   "source": [
    "# Save the new file\n",
    "\n",
    "# Specify the folder path to save the JSON file\n",
    "folder_path = \"../_datasets/Clean\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Define the filename for the JSON file\n",
    "filename = \"continent_data_2.json\"\n",
    "\n",
    "# Generate the file path\n",
    "file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Save the continent JSON to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    json.dump(continent_data, file, indent=4)\n",
    "\n",
    "print(f\"JSON data saved to: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67232512-4f87-4cb3-b1e8-e31082f43761",
   "metadata": {},
   "source": [
    "QUESTA PARTE PER ORA NON LA USIAMO - CANCELLO IL JSON CREATO NELLA CARTELLA CLEAN PER NON FARE CONFUSIONE.\n",
    "\n",
    "SE SARÀ NECESSARIO AVERE I DATI DELLA DISTRIBUZIONE PER REGIONE DEI NUOVI MIGRANTI SI PUÒ ESPORTARE NUOVAMENTE.\n",
    "\n",
    "## RETRIVING GEOGRAPHICAL ARRIVAL FOR TOTAL IMMIGRANTS.\n",
    "\n",
    "We will use the same dataset for two different measures. We saw the one and we will also retrive the distribution of total immigrants divided by region.\n",
    "\n",
    "In order to do so we will mantain the same filters besides for the \n",
    "\n",
    "- \"CITIZENSHIP\" whete the geopolitical origin is declared, we will select the total.\n",
    "- \"TERRITORY_NEXT_RESID\" for the new residence's geographic area. In our case we decided to look at group of regions, level NUTS 1 (Nomenclature of Territorial Units for Statistics). So we filter for: ITC for Northwest Italy; ITD for Northeast Italy; ITE for Central Italy; ITF for South Italy; ITG Insular Italy (Sicily and Sardinia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97b39172-0be5-4f2a-9186-e83da392fed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 - QUERY WITH FILTERS\n",
    "# Query all immigrants from the whole world, both sexes, every age, divided by region of arrival.\n",
    "response = requests.get('https://esploradati.istat.it/SDMXWS/rest/data/28_185/A..TREG.FREIGN..9.TOTAL.ITC+ITD+ITE+ITF+ITG.X1033.X1033')\n",
    "print(response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = response.content\n",
    "    \n",
    "    if len(content) > 0:\n",
    "        try:\n",
    "            xml_data = xmltodict.parse(content)\n",
    "            json_string_data = json.dumps(xml_data,\n",
    "                                    allow_nan = True, # If we hadn't set allow_nan to\n",
    "                                                      # true we would have got\n",
    "                                                      # ValueError: Out of range float\n",
    "                                                      # values are not JSON compliant\n",
    "                                    indent = 6) # Indentation can be used for pretty-printing\n",
    "            # Now you can work with the parsed JSON data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    else:\n",
    "        print(\"Empty content received.\")\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n",
    "\n",
    "# print(json_string_data)\n",
    "type(json_string_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e39923ff-3e61-4456-a666-6c9fdb449a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_data = {}\n",
    "\n",
    "series = data['message:GenericData']['message:DataSet']['generic:Series']\n",
    "\n",
    "for s in series:\n",
    "    series_key = s['generic:SeriesKey']['generic:Value']\n",
    "    obs = s['generic:Obs']\n",
    "\n",
    "    region = None\n",
    "\n",
    "    for key in series_key:\n",
    "        if key['@id'] == 'TERRITORY_NEXT_RESID':\n",
    "            region = key['@value']\n",
    "            break\n",
    "\n",
    "    if region:\n",
    "        if region not in region_data:\n",
    "            region_data[region] = []\n",
    "\n",
    "        for o in obs:\n",
    "            year = int(o['generic:ObsDimension']['@value'])\n",
    "            value = o['generic:ObsValue']['@value']\n",
    "\n",
    "            # Set the year as a date type with the last day of the year\n",
    "            year_date = datetime(year=year, month=12, day=31)\n",
    "\n",
    "            region_data[region].append({\"date\": year_date.strftime(\"%Y-%m-%d\"), \"tot_immigrants\": int(value)})\n",
    "\n",
    "# Convert the region data to JSON\n",
    "region_json = json.dumps(region_data, indent=4)\n",
    "\n",
    "# print(region_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f1f1515-f730-4e20-ae8f-95f0de4e6c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data saved to: ../_datasets/Clean/regional_immigration_data.json\n"
     ]
    }
   ],
   "source": [
    "# Save the new file\n",
    "\n",
    "# Specify the folder path to save the JSON file\n",
    "folder_path = \"../_datasets/Clean\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Define the filename for the JSON file\n",
    "filename = \"regional_immigration_data.json\"\n",
    "\n",
    "# Generate the file path\n",
    "file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Save the continent JSON to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    json.dump(region_data, file, indent=4)\n",
    "\n",
    "print(f\"JSON data saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638dfafb-7dd5-4ff1-aebd-71a63a465c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
